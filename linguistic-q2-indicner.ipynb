{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install transformers\n!pip3 install datasets\n!pip3 install sentencepiece\n!pip install seqeval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-12T15:39:41.902219Z","iopub.execute_input":"2024-03-12T15:39:41.902635Z","iopub.status.idle":"2024-03-12T15:40:38.209621Z","shell.execute_reply.started":"2024-03-12T15:39:41.902602Z","shell.execute_reply":"2024-03-12T15:40:38.208394Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m594.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=6f89136709afc7da03424b555a315b57df89099021660e981d53201e4807664c\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Fine Tuning the IndicNER Model**","metadata":{}},{"cell_type":"markdown","source":"**Naampadam Dataset**","metadata":{}},{"cell_type":"code","source":"# Let's download the Naampadam (Indic NER) dataset\nfrom datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n\nlang='gu'\n\nraw_datasets = load_dataset('ai4bharat/naamapadam', lang)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:37:14.146410Z","iopub.execute_input":"2024-03-12T15:37:14.146780Z","iopub.status.idle":"2024-03-12T15:38:31.100436Z","shell.execute_reply.started":"2024-03-12T15:37:14.146750Z","shell.execute_reply":"2024-03-12T15:38:31.099510Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4ff457b82e4cb6a8c3803c92f6dd68"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset naamapadam_pr/gu to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/gu/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/26.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f03a30a9834840e29462454ad46d6ff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset naamapadam_pr downloaded and prepared to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/gu/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20b6d8f661cc4e108c0ab1436ffec3b4"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:38:05.937447Z","iopub.execute_input":"2024-03-12T12:38:05.937838Z","iopub.status.idle":"2024-03-12T12:38:05.943645Z","shell.execute_reply.started":"2024-03-12T12:38:05.937784Z","shell.execute_reply":"2024-03-12T12:38:05.942678Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags'],\n        num_rows: 472845\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags'],\n        num_rows: 1076\n    })\n    validation: Dataset({\n        features: ['tokens', 'ner_tags'],\n        num_rows: 2389\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets.column_names","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:38:43.510683Z","iopub.execute_input":"2024-03-12T15:38:43.511030Z","iopub.status.idle":"2024-03-12T15:38:43.517405Z","shell.execute_reply.started":"2024-03-12T15:38:43.510994Z","shell.execute_reply":"2024-03-12T15:38:43.516580Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'train': ['tokens', 'ner_tags'],\n 'test': ['tokens', 'ner_tags'],\n 'validation': ['tokens', 'ner_tags']}"},"metadata":{}}]},{"cell_type":"code","source":"# let's print an instance of dataset\nidx=0\nrec=raw_datasets['train'][idx]\nfor w, t in zip(rec['tokens'],rec['ner_tags']):\n  print('{}\\t{}'.format(w,t))","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:38:47.291477Z","iopub.execute_input":"2024-03-12T15:38:47.291826Z","iopub.status.idle":"2024-03-12T15:38:47.299800Z","shell.execute_reply.started":"2024-03-12T15:38:47.291798Z","shell.execute_reply":"2024-03-12T15:38:47.298968Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"લક્ઝરી\t0\nસેન્ટ\t5\nએન્ડ્રુ\t6\nમાતાનો\t6\nચર્ચ\t6\n","output_type":"stream"}]},{"cell_type":"code","source":"features = raw_datasets[\"train\"].features\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:38:50.787093Z","iopub.execute_input":"2024-03-12T15:38:50.787894Z","iopub.status.idle":"2024-03-12T15:38:50.792564Z","shell.execute_reply.started":"2024-03-12T15:38:50.787861Z","shell.execute_reply":"2024-03-12T15:38:50.791573Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n","output_type":"stream"}]},{"cell_type":"code","source":"text_column_name = \"tokens\"\nlabel_column_name = \"ner_tags\"","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:38:52.360085Z","iopub.execute_input":"2024-03-12T15:38:52.360705Z","iopub.status.idle":"2024-03-12T15:38:52.364943Z","shell.execute_reply.started":"2024-03-12T15:38:52.360676Z","shell.execute_reply":"2024-03-12T15:38:52.363824Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"label_list = features[label_column_name].feature.names\n\nlabel_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n\nprint(label_list)\n\nnum_labels = len(label_list)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:38:54.061513Z","iopub.execute_input":"2024-03-12T15:38:54.062621Z","iopub.status.idle":"2024-03-12T15:38:54.068101Z","shell.execute_reply.started":"2024-03-12T15:38:54.062578Z","shell.execute_reply":"2024-03-12T15:38:54.067120Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Training an NER Model with the dataset**","metadata":{}},{"cell_type":"markdown","source":"**Load Pre-trained Model**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\nimport numpy as np\n\nconfig = AutoConfig.from_pretrained('ai4bharat/IndicNER', num_labels=num_labels, finetuning_task='ner')\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\nmodel = AutoModelForTokenClassification.from_pretrained('ai4bharat/IndicNER', num_labels=num_labels )","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:38:55.957389Z","iopub.execute_input":"2024-03-12T15:38:55.957783Z","iopub.status.idle":"2024-03-12T15:39:01.708462Z","shell.execute_reply.started":"2024-03-12T15:38:55.957754Z","shell.execute_reply":"2024-03-12T15:39:01.707647Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91909365090b4f6993241312172c7edc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/346 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94aaa20307644ba09a682b8db37cfea5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c869b2a2ded4b8dba66a4394e262b7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5228f0d184a44438a4a7f1ac9582e97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3adad1a983b5451982608d646bc81192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/667M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b83e17f7bf74621a99b6aa29f84e3ee"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tokenize all texts and align the labels with them**","metadata":{}},{"cell_type":"code","source":"# Tokenize all texts and align the labels with them.\npadding = \"max_length\"\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[text_column_name],\n        padding=padding,\n        truncation=True,\n        max_length=512,\n        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n        is_split_into_words=True,\n    )\n    labels = []\n    for i, label in enumerate(examples[label_column_name]):\n        # print('=====')\n        # print('{} {}'.format(i,label)) #ak\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n            # ignored in the loss function.\n            if word_idx is None:\n                label_ids.append(-100)\n            # We set the label for the first token of each word.\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n            # the label_all_tokens flag.\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:39:06.608835Z","iopub.execute_input":"2024-03-12T15:39:06.609616Z","iopub.status.idle":"2024-03-12T15:39:06.617403Z","shell.execute_reply.started":"2024-03-12T15:39:06.609580Z","shell.execute_reply":"2024-03-12T15:39:06.616468Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Let us not tokenize the train and validation**","metadata":{}},{"cell_type":"code","source":"train_dataset = raw_datasets[\"train\"]\n# train_dataset = train_dataset.map(\n#     tokenize_and_align_labels,\n#     batched=True,\n#     num_proc=4,\n#     load_from_cache_file=True,\n#     desc=\"Running tokenizer on train dataset\",\n# )\nsubset_train_dataset = train_dataset.select(range(20000))\nsubset_train_dataset = subset_train_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on subset of train dataset\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:39:10.416724Z","iopub.execute_input":"2024-03-12T15:39:10.417467Z","iopub.status.idle":"2024-03-12T15:39:16.891911Z","shell.execute_reply.started":"2024-03-12T15:39:10.417417Z","shell.execute_reply":"2024-03-12T15:39:16.890943Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on subset of train dataset #0:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"120c1ae3807b4388bc124f6f7ade2ffb"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on subset of train dataset #1:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e102f3fcef3d41cda1716bdc3da6a322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on subset of train dataset #2:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c322976a8aec41c9b849eaeba597f260"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on subset of train dataset #3:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c280adf79ab4febae92b807333306ce"}},"metadata":{}}]},{"cell_type":"code","source":"eval_dataset = raw_datasets[\"validation\"]\nsubset_eval_dataset = eval_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on Validation dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:39:18.782814Z","iopub.execute_input":"2024-03-12T15:39:18.783838Z","iopub.status.idle":"2024-03-12T15:39:19.858334Z","shell.execute_reply.started":"2024-03-12T15:39:18.783797Z","shell.execute_reply":"2024-03-12T15:39:19.857170Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0bf0150b5d545daba73906f93293264"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1fb618401594115a51e01575c405975"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ad622b5a9bd4aaeb3a9dbf95fc8189e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81cae87594a44b428f1767a8f4f195ae"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Create Data Collator, Metrics**","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:39:26.323962Z","iopub.execute_input":"2024-03-12T15:39:26.324631Z","iopub.status.idle":"2024-03-12T15:39:26.328567Z","shell.execute_reply.started":"2024-03-12T15:39:26.324597Z","shell.execute_reply":"2024-03-12T15:39:26.327686Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Metrics\nmetric = load_metric(\"seqeval\")\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    # results = metric.compute(predictions=true_predictions, references=true_labels)\n    # Unpack nested dictionaries\n    # final_results = {}\n    # for key, value in results.items():\n    #     if isinstance(value, dict):\n    #         for n, v in value.items():\n    #             final_results[f\"{key}_{n}\"] = v\n    #     else:\n    #         final_results[key] = value\n    # return final_results\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    # Unpack nested dictionaries\n    final_results = {}\n    for key, value in results.items():\n        if isinstance(value, dict):\n            for n, v in value.items():\n                final_results[f\"{key}_{n}\"] = v\n        else:\n            final_results[key] = value\n    return final_results","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:40:51.110845Z","iopub.execute_input":"2024-03-12T15:40:51.111224Z","iopub.status.idle":"2024-03-12T15:40:51.362790Z","shell.execute_reply.started":"2024-03-12T15:40:51.111193Z","shell.execute_reply":"2024-03-12T15:40:51.362058Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Set Training Arguments**","metadata":{}},{"cell_type":"code","source":"batch_size=16\nargs=TrainingArguments(\n    output_dir='output_dir',\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=4,\n    evaluation_strategy = \"epoch\",\n    learning_rate=5e-7)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:41:24.913268Z","iopub.execute_input":"2024-03-12T15:41:24.913641Z","iopub.status.idle":"2024-03-12T15:41:24.981575Z","shell.execute_reply.started":"2024-03-12T15:41:24.913611Z","shell.execute_reply":"2024-03-12T15:41:24.980846Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    train_dataset=subset_train_dataset,\n    eval_dataset=subset_eval_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    # callbacks=[early_stopping_callback],\n    args=args,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:41:27.620639Z","iopub.execute_input":"2024-03-12T15:41:27.621431Z","iopub.status.idle":"2024-03-12T15:41:29.382481Z","shell.execute_reply.started":"2024-03-12T15:41:27.621396Z","shell.execute_reply":"2024-03-12T15:41:29.381718Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"trainer.args","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:41:29.701064Z","iopub.execute_input":"2024-03-12T15:41:29.701753Z","iopub.status.idle":"2024-03-12T15:41:29.709566Z","shell.execute_reply.started":"2024-03-12T15:41:29.701722Z","shell.execute_reply":"2024-03-12T15:41:29.708421Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=2,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=None,\nevaluation_strategy=epoch,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=5e-07,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=output_dir/runs/Mar12_15-41-24_64208d623cc8,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=4,\noptim=adamw_torch,\noptim_args=None,\noutput_dir=output_dir,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=16,\nper_device_train_batch_size=16,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nresume_from_checkpoint=None,\nrun_name=output_dir,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=500,\nsave_strategy=steps,\nsave_total_limit=None,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=0,\nweight_decay=0.0,\n)"},"metadata":{}}]},{"cell_type":"code","source":"train_result = trainer.train()\nmetrics = train_result.metrics\n# Assuming `metrics` is a dictionary containing the training metrics\nwith open(\"training_metrics.txt\", \"w\") as file:\n    for key, value in metrics.items():\n        file.write(f\"{key}: {value}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T15:41:32.772970Z","iopub.execute_input":"2024-03-12T15:41:32.773819Z","iopub.status.idle":"2024-03-12T16:51:09.788645Z","shell.execute_reply.started":"2024-03-12T15:41:32.773788Z","shell.execute_reply":"2024-03-12T16:51:09.787437Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240312_154138-pc88qy77</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nijpadariya/huggingface/runs/pc88qy77' target=\"_blank\">ruby-mountain-11</a></strong> to <a href='https://wandb.ai/nijpadariya/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nijpadariya/huggingface' target=\"_blank\">https://wandb.ai/nijpadariya/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nijpadariya/huggingface/runs/pc88qy77' target=\"_blank\">https://wandb.ai/nijpadariya/huggingface/runs/pc88qy77</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 1:08:54, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Loc Precision</th>\n      <th>Loc Recall</th>\n      <th>Loc F1</th>\n      <th>Loc Number</th>\n      <th>Org Precision</th>\n      <th>Org Recall</th>\n      <th>Org F1</th>\n      <th>Org Number</th>\n      <th>Per Precision</th>\n      <th>Per Recall</th>\n      <th>Per F1</th>\n      <th>Per Number</th>\n      <th>Overall Precision</th>\n      <th>Overall Recall</th>\n      <th>Overall F1</th>\n      <th>Overall Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>6.738900</td>\n      <td>2.881739</td>\n      <td>0.000172</td>\n      <td>0.000828</td>\n      <td>0.000285</td>\n      <td>1208</td>\n      <td>0.020333</td>\n      <td>0.010377</td>\n      <td>0.013741</td>\n      <td>1060</td>\n      <td>0.137566</td>\n      <td>0.193189</td>\n      <td>0.160700</td>\n      <td>1615</td>\n      <td>0.037578</td>\n      <td>0.083441</td>\n      <td>0.051819</td>\n      <td>0.051778</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.801200</td>\n      <td>0.748460</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1208</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1060</td>\n      <td>0.247294</td>\n      <td>0.183901</td>\n      <td>0.210938</td>\n      <td>1615</td>\n      <td>0.172674</td>\n      <td>0.076487</td>\n      <td>0.106015</td>\n      <td>0.798603</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.759500</td>\n      <td>0.599956</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1208</td>\n      <td>0.028807</td>\n      <td>0.006604</td>\n      <td>0.010744</td>\n      <td>1060</td>\n      <td>0.339776</td>\n      <td>0.413622</td>\n      <td>0.373080</td>\n      <td>1615</td>\n      <td>0.255006</td>\n      <td>0.173835</td>\n      <td>0.206738</td>\n      <td>0.812762</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.569500</td>\n      <td>0.564811</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1208</td>\n      <td>0.033210</td>\n      <td>0.008491</td>\n      <td>0.013524</td>\n      <td>1060</td>\n      <td>0.357075</td>\n      <td>0.468731</td>\n      <td>0.405355</td>\n      <td>1615</td>\n      <td>0.274650</td>\n      <td>0.197270</td>\n      <td>0.229616</td>\n      <td>0.816762</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmetrics = trainer.evaluate()\n\ntrainer.log_metrics(\"eval\", metrics)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T13:43:12.204081Z","iopub.execute_input":"2024-03-12T13:43:12.204519Z","iopub.status.idle":"2024-03-12T13:44:06.847359Z","shell.execute_reply.started":"2024-03-12T13:43:12.204478Z","shell.execute_reply":"2024-03-12T13:44:06.846088Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [150/150 00:52]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =        3.0\n  eval_LOC_f1             =     0.8068\n  eval_LOC_number         =       1208\n  eval_LOC_precision      =     0.7898\n  eval_LOC_recall         =     0.8245\n  eval_ORG_f1             =     0.7159\n  eval_ORG_number         =       1060\n  eval_ORG_precision      =     0.7058\n  eval_ORG_recall         =     0.7264\n  eval_PER_f1             =     0.8114\n  eval_PER_number         =       1615\n  eval_PER_precision      =     0.7974\n  eval_PER_recall         =      0.826\n  eval_loss               =     0.1966\n  eval_overall_accuracy   =     0.9414\n  eval_overall_f1         =      0.784\n  eval_overall_precision  =     0.7702\n  eval_overall_recall     =     0.7984\n  eval_runtime            = 0:00:54.61\n  eval_samples_per_second =      43.74\n  eval_steps_per_second   =      2.746\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Evaluate the Trained Model**","metadata":{}},{"cell_type":"markdown","source":"**Let us now evaluate the trained model on the test sets of all languages**","metadata":{}},{"cell_type":"markdown","source":"**We need to first tokenize the test sets**","metadata":{}},{"cell_type":"code","source":"test_dataset = raw_datasets[\"test\"]\ntest_dataset = test_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on Test dataset\",\n)\nprint(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T17:25:46.813753Z","iopub.execute_input":"2024-03-12T17:25:46.814522Z","iopub.status.idle":"2024-03-12T17:25:47.549781Z","shell.execute_reply.started":"2024-03-12T17:25:46.814488Z","shell.execute_reply":"2024-03-12T17:25:47.547771Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Test dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90c2b70454694eefa157c02ff578d450"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Test dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59a6ffa0e4884d67ab0ca367cb4cb4e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Test dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5c588c809c04815923683de772a52ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Test dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ca100a11cfb4b8abdc4f8aa6226805c"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 1076\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Run prediction on test set of each of the language separately and extract overall Precison, Recall and F-Score separately**","metadata":{}},{"cell_type":"code","source":"predictions, labels, metrics = trainer.predict(test_dataset, metric_key_prefix=lang)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T17:25:52.774625Z","iopub.execute_input":"2024-03-12T17:25:52.775007Z","iopub.status.idle":"2024-03-12T17:26:14.553477Z","shell.execute_reply.started":"2024-03-12T17:25:52.774971Z","shell.execute_reply":"2024-03-12T17:26:14.552247Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"lang_specific_results = {}\nfor key in metrics:\n    if 'overall_precision' in key:\n      lang_specific_results['Precision'] = metrics[key]\n    elif 'overall_recall' in key:\n      lang_specific_results['Recall'] = metrics[key]\n    elif 'overall_f1' in key:\n      lang_specific_results['macro-F1 Score'] = metrics[key]","metadata":{"execution":{"iopub.status.busy":"2024-03-12T17:26:27.017043Z","iopub.execute_input":"2024-03-12T17:26:27.017402Z","iopub.status.idle":"2024-03-12T17:26:27.028076Z","shell.execute_reply.started":"2024-03-12T17:26:27.017375Z","shell.execute_reply":"2024-03-12T17:26:27.026983Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(lang_specific_results)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T17:26:31.456134Z","iopub.execute_input":"2024-03-12T17:26:31.457108Z","iopub.status.idle":"2024-03-12T17:26:31.463110Z","shell.execute_reply.started":"2024-03-12T17:26:31.457073Z","shell.execute_reply":"2024-03-12T17:26:31.462068Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"{'Precision': 0.2912698412698413, 'Recall': 0.21067738231917335, 'macro-F1 Score': 0.24450366422385075}\n","output_type":"stream"}]}]}